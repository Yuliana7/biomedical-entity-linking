{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4. Experiment with a different embedding model\n",
    "\n",
    "The previous parts of the research focused on developing a combined strategy using BAAI embeddings. In this part we will recreate the experiment with LLAMA3 embeddings and compare the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "from utils.generic import get_driver, Models, Vectors\n",
    "from utils.evalutation import (\n",
    "    mrr_score,\n",
    "    hits_at_n_score,\n",
    ")\n",
    "from utils.index_search_helpers import (predict_with_vector_index,\n",
    "                                        get_embedding_col_name,\n",
    "                                        vector_index_query,\n",
    "                                        get_combined_search_for_df\n",
    "                                        )\n",
    "from utils.index_update_helpers import batch_update_synonym_centorid_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = get_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/ncbi_specific_disease_singular_id.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector indices on LLAMA3 embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, we need to create embeddings for `Description` in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model =OllamaEmbedding(\n",
    "    model_name=\"llama3\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "\n",
    "df['DiseaseEmbedding-llama3'] = df['Description'].apply(lambda text: embed_model.get_text_embedding(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/ncbi_specific_disease_singular_id.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already created LLAMA3 embeddings for `DiseaseName` and `Synonyms` during the data processing step, now we can create centroid of synonyms embeddings and update the knowledge graph with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_update_synonym_centorid_embeddings(driver=driver, embedding_model_name=Models.LLAMA3.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create vector index for it. The length of Llama 3 model's embedding is 4096, thus we will indicate it as `vector.dimensions` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_llama3_synonyms_combined_vector_index_query = \"\"\"\n",
    "    CREATE VECTOR INDEX llama3VectorIndex_combinedSynonym IF NOT EXISTS\n",
    "    FOR (d:Disease)\n",
    "    ON d.`SynonymsCentroidEmbedding-llama3`\n",
    "    OPTIONS {\n",
    "        indexConfig: {\n",
    "            `vector.dimensions`: 4096,\n",
    "            `vector.similarity_function`: 'cosine'\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "create_llama3_disease_name_vector_index_query = \"\"\"\n",
    "    CREATE VECTOR INDEX llama3VectorIndex IF NOT EXISTS\n",
    "    FOR (d:Disease)\n",
    "    ON d.`DiseaseEmbedding-llama3`\n",
    "    OPTIONS {\n",
    "        indexConfig: {\n",
    "            `vector.dimensions`: 4096,\n",
    "            `vector.similarity_function`: 'cosine'\n",
    "        }\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.run(create_llama3_synonyms_combined_vector_index_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.run(create_llama3_disease_name_vector_index_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test these indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values_name_vector = predict_with_vector_index(\n",
    "    driver=driver,\n",
    "    index=\"llama3VectorIndex\",\n",
    "    query=vector_index_query,\n",
    "    dataset=df,\n",
    "    embedding_col=get_embedding_col_name(Models.LLAMA3, 'DiseaseEmbedding'),\n",
    "    limit=10,\n",
    "    threshold=0.8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1050902311434035"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_score(predicted_values_name_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09273054199845877"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_at_n_score(predicted_values_name_vector, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12098638582070383"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_at_n_score(predicted_values_name_vector, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values_syn_vector = predict_with_vector_index(\n",
    "    driver=driver,\n",
    "    index=\"llama3VectorIndex_combinedSynonym\",\n",
    "    query=vector_index_query,\n",
    "    dataset=df,\n",
    "    embedding_col=get_embedding_col_name(Models.LLAMA3, 'DiseaseEmbedding'),\n",
    "    limit=10,\n",
    "    threshold=0.8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022950228126184975"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_score(predicted_values_syn_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01592602106344721"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_at_n_score(predicted_values_syn_vector, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033650141279219115"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_at_n_score(predicted_values_syn_vector, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the results from using these queries in isolation are not very  promising. Now let us search with a combined search strategy like we did for BAAI embeddings and compare the results.\n",
    "The best results with a limit=100 for BAAI embeddings were:\n",
    "- accuracy: 0.6696634985872079 (baseline: 0.52520366598778)\n",
    "- mrr score: 0.7013352845422232\n",
    "- hit@5 score: 0.7467248908296943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_limit_10 = get_combined_search_for_df(\n",
    "    dataset=df,\n",
    "    embedding_col=get_embedding_col_name(Models.LLAMA3, 'DiseaseEmbedding'),\n",
    "    driver=driver,\n",
    "    limit=10,\n",
    "    name_vec_index=Vectors.LLAMA3_DISEASE_NAME.value,\n",
    "    centoid_vec_index=Vectors.LLAMA3_DISEASE_SYNONYMS_CENTROID.value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64882012484761"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_score(combined_search_limit_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6175186231697919"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_at_n_score(combined_search_limit_10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6884151040328795"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_at_n_score(combined_search_limit_10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an immediate improvement for the same limit=10, however, let us compare the accuracy if we allow 100 candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_limit_100 = get_combined_search_for_df(\n",
    "    dataset=df,\n",
    "    embedding_col=get_embedding_col_name(Models.LLAMA3, 'DiseaseEmbedding'),\n",
    "    driver=driver,\n",
    "    limit=100,\n",
    "    name_vec_index=Vectors.LLAMA3_DISEASE_NAME.value,\n",
    "    centoid_vec_index=Vectors.LLAMA3_DISEASE_SYNONYMS_CENTROID.value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6517433872628721"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_score(combined_search_limit_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6175186231697919"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_at_n_score(combined_search_limit_100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6884151040328795"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_at_n_score(combined_search_limit_100, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the results are not dramatically better for a larger limit. Let us now summarize these findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results analysis and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual hypothesis is that the larger the embedding model - the better it captures nuances of the target language and thus produces better results. However, as we can see from the experiment above - this is not the case for Llama3 embeddings.\n",
    "As we confirmed via these experiments, the choice of the embedding model has an influence of the accuracy of the predictions, however, the combinations of different search strategies alongside using heuristic methods for accuracy boosting that is suitable for the domain proved to be more effective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
