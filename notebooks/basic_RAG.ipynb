{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4b7910c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "from pathlib import Path\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "from mistral_inference.model import Transformer\n",
        "from mistral_inference.generate import generate\n",
        "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
        "from mistral_common.protocol.instruct.messages import UserMessage\n",
        "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "271320b6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 3 files: 100%|██████████| 3/3 [42:42<00:00, 854.02s/it]   \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/Users/yuliana.romaniv/mistral_models/7B-v0.3'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#from src.config import Config\n",
        "\n",
        "mistral_models_path = Path.home().joinpath('mistral_models', '7B-v0.3')\n",
        "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "snapshot_download(repo_id=\"mistralai/Mistral-7B-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir=mistral_models_path, token=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c928bfe1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yuliana.romaniv/University/AstraZeneca/test-rag/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# loads BAAI/bge-small-en-v1.5\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "97a06f98",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "384\n",
            "[-0.003275736467912793, -0.011690806597471237, 0.04155921936035156, -0.03814813494682312, 0.02418307028710842]\n"
          ]
        }
      ],
      "source": [
        "embeddings = embed_model.get_text_embedding(\"Hello World!\")\n",
        "print(len(embeddings))\n",
        "print(embeddings[:5])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "formats": "ipynb,py:light"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
