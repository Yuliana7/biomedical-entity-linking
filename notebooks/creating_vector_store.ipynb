{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.neo4jvector import Neo4jVectorStore\n",
    "from llama_index.core import StorageContext, ServiceContext, VectorStoreIndex\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generic import get_driver, get_credentials, Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "/Users/yuliana.romaniv/University/AstraZeneca/test-rag/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "driver = get_driver()\n",
    "embed_model = HuggingFaceEmbedding(model_name=Models.BAAI_BGE_SMALL_EN_V1_5.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df = pd.read_csv('../data/processed/ncbi_dev_abstracts.csv')\n",
    "annotations_df = pd.read_csv('../data/processed/ncbi_dev_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 384  # BAAI/bge-small-en-v1.5 embedding dimension\n",
    "uri = get_credentials('uri')\n",
    "username = get_credentials('username')\n",
    "password = get_credentials('password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_vector_hybrid_BAAI = Neo4jVectorStore(\n",
    "    url=uri,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    hybrid_search=True,\n",
    "    embedding_dimension=embedding_dimension,\n",
    "    embedding_node_property=\"DiseaseEmbedding-BAAI-bge-small-en-v1_5\",\n",
    "    text_node_property=\"DiseaseName\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context_BAAI = StorageContext.from_defaults(\n",
    "    vector_store=neo4j_vector_hybrid_BAAI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v7/qc3t6kss0r7ffhlp7bzsz0zc0000gp/T/ipykernel_18734/3785188565.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context_BAAI = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "service_context_BAAI = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model,\n",
    "    llm=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_graph_data(driver):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (n) RETURN n\")\n",
    "        nodes = []\n",
    "        for record in result:\n",
    "            node = record[\"n\"]\n",
    "            nodes.append(node)\n",
    "    return nodes\n",
    "\n",
    "nodes = extract_graph_data(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_to_documents(nodes):\n",
    "    documents = []\n",
    "    for node in nodes:\n",
    "        try:\n",
    "            # Create a combined text from node properties for the document content\n",
    "            content = \" \".join([f\"{key}: {value}\" for key, value in node.items()])\n",
    "            doc = Document(\n",
    "                text=content,\n",
    "                metadata={\"labels\": list(node.labels), \"element_id\": node.element_id}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing node {node.element_id}: {e}\")\n",
    "    return documents\n",
    "\n",
    "documents = nodes_to_documents(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdd68895815494d8370466dcc5653a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/13298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Error creating vector store index: The `model_name` argument must be provided.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    index_BAAI = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context_BAAI,\n",
    "        service_context=service_context_BAAI,\n",
    "        show_progress=True,\n",
    "        embed_model='local',\n",
    "    )\n",
    "    logger.info(\"Vector store index created successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error creating vector store index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_BAAI = index_BAAI.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"This patient has glucose-6-phosphate dehydrogenase (G6PD) deficiency.\"\n",
    "results = query_engine_BAAI.query(query)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../db/vector_store/vector_store_index_BAAI.pkl', 'wb') as f:\n",
    "    pickle.dump(index_BAAI, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
